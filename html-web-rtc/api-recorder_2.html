<!DOCTYPE html>

<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <title>Live input record and playback</title>
  <link rel="icon" href="../assets/images/logo.ico" type="image/png">
  <style type='text/css'>
    ul {
      list-style: none;
    }

    #recordingslist audio {
      display: block;
      margin-bottom: 10px;
    }

  </style>
</head>

<body>

  <h1>Recorder.js simple WAV export example</h1>

  <p>Make sure you are using a recent version of Google Chrome.</p>
  <p>Also before you enable microphone input either plug in headphones or turn the volume down if you want to avoid ear
    splitting feedback!</p>

  <canvas id="audio-line"></canvas>

  <button class="start-record">record</button>
  <button class="stop-record" disabled>stop</button>
  <!-- <button onclick="pauseRecording(this);">pause</button>
  <button onclick="resumeRecording(this);">resume</button> -->

  <h2>Recordings</h2>
  <ul id="recordingslist"></ul>

  <h2>Log</h2>
  <pre id="log"></pre>


  <script src="/workers/test/js/traceur.js"></script>

  <script type="module">
    import Recorder from './record/recorder.js'
    // console.info(Recorder)

    function __log(e, data) {
      log.innerHTML += "\n" + e + " " + (data || '');
    }

    let audio_context;
    let recorder;
    let realStream
    let waveAudioCtx
    let canvas = document.querySelector('#audio-line')
    let canvasCtx = canvas.getContext('2d')
    let drawVisual = null
    

    document.querySelector('.start-record').addEventListener('click', (e) => {
      const button = e.target

      recorder && recorder.record();
      button.disabled = true;
      button.nextElementSibling.disabled = false;
      __log('Recording...');
    })

    document.querySelector('.stop-record').addEventListener('click', (e) => {
      const button = e.target

      recorder && recorder.stop();
      button.disabled = true;
      button.previousElementSibling.disabled = false;
      __log('Stopped recording.');

      // create WAV download link using audio data blob
      createDownloadLink();
    })

    // function startRecording(button) {
    //   recorder && recorder.record();
    //   button.disabled = true;
    //   button.nextElementSibling.disabled = false;
    //   __log('Recording...');
    // }

    // function stopRecording(button) {
    //   recorder && recorder.stop();
    //   button.disabled = true;
    //   button.previousElementSibling.disabled = false;
    //   __log('Stopped recording.');

    //   // create WAV download link using audio data blob
    //   createDownloadLink();

    //   recorder.clear();
    // }

    function createDownloadLink() {
      recorder && recorder.exportWAV(function (blob) {
        var url = URL.createObjectURL(blob);
        var li = document.createElement('li');
        var au = document.createElement('audio');
        var hf = document.createElement('a');

        __log('**url**', url)

        au.controls = true;
        au.src = url;
        hf.href = url;
        hf.download = new Date().toISOString() + '.wav';
        hf.innerHTML = hf.download;
        li.appendChild(au);
        li.appendChild(hf);
        recordingslist.appendChild(li);
      });
    }

    function createAudioWave(stream) {
      waveAudioCtx = new AudioContext()
      const waveSource = waveAudioCtx.createMediaStreamSource(stream)

      const gainNode = waveAudioCtx.createGain()
      gainNode.gain.value = 5
      waveSource.connect(gainNode)

      const analyseNode = waveAudioCtx.createAnalyser()
      analyseNode.fftSize = 2048;
      const bufferLength = analyseNode.fftSize;
      const dataArray = new Uint8Array(bufferLength);
      analyseNode.getByteTimeDomainData(dataArray)

      gainNode.connect(analyseNode)

      function draw() {
        drawVisual = requestAnimationFrame(draw);

        let WIDTH = 400
        let HEIGHT = 150

        analyseNode.getByteTimeDomainData(dataArray);

        canvasCtx.fillStyle = 'rgb(200, 200, 200)';
        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

        canvasCtx.beginPath();

        var sliceWidth = WIDTH * 1.0 / bufferLength;
        var x = 0;

        for(var i = 0; i < bufferLength; i++) {

          var v = dataArray[i] / 128.0;
          var y = v * HEIGHT/2;

          if(i === 0) {
            canvasCtx.moveTo(x, y);
          } else {
            canvasCtx.lineTo(x, y);
          }

          x += sliceWidth;
        }

        canvasCtx.lineTo(canvas.width, canvas.height/2);
        canvasCtx.stroke();
        };

        draw()

        setTimeout(() => {
          waveAudioCtx.suspend()
        }, 5000)

        setTimeout(() => {
          waveAudioCtx.resume()
        }, 10000)
      }    

    window.onload = function init() {
      audio_context = new AudioContext()
      navigator.mediaDevices.getUserMedia({
        audio: true
      }).then(stream => {
        realStream = stream

        const input = audio_context.createMediaStreamSource(stream);
        __log('Media stream created.');
        
        createAudioWave(stream)

        // Uncomment if you want the audio to feedback directly
        //input.connect(audio_context.destination);
        //__log('Input connected to audio context destination.');

        recorder = new Recorder(input);
        __log('Recorder initialised.');
      }).catch(err => {
        __log('No live audio input: ' + e);
      })
    };
  
    window.onunload = function() {
      cancelAnimationFrame(drawVisual)
    }
  </script>

</body>

</html>
